{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "import json\n",
    "\n",
    "from fycharts.SpotifyCharts import SpotifyCharts\n",
    "import sqlalchemy\n",
    "\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../spotify_credentials.json\", \"r\") as json_file:\n",
    "    creds = json.load(json_file)\n",
    "\n",
    "my_client_id = creds['SPOTIPY_CLIENT_ID']\n",
    "my_client_secret = creds['SPOTIPY_CLIENT_SECRET']\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=my_client_id, client_secret=my_client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_200_weekly(output_file, output_db, start_date, end_date, region):\n",
    "    api = SpotifyCharts()\n",
    "    connector = sqlalchemy.create_engine(\"sqlite:///../data/italy_2017.db\", echo=False)\n",
    "api.top200Weekly(output_file = \"../data/italy_2017.csv\", output_db = connector, webhook = [\"https://mywebhookssite.com/post/\"], start = \"2017-01-01\", end = \"2017-12-31\", region = \"it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_song_features_df(df, cols_to_drop, pickle_path):\n",
    "    \n",
    "    # drop unnecessary columns \n",
    "    df.drops(columns=cols_to_drop, inplace=True)\n",
    "    \n",
    "    # convert date column date range to a single day that is the first date in the range (happens to be the Friday of that week)\n",
    "    df['date'] = df['date'].apply(lambda x: x[:10])\n",
    "    \n",
    "    # converting date column to datetime format\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    # setting date column as df index\n",
    "    df.set_index('date', inplace=True)\n",
    "    \n",
    "    # pickle clean dataframe to use in other notebooks \n",
    "    df.to_pickle(pickle_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deg_merge_audio_features(song_df, id_col, batchsize=100):\n",
    "    \n",
    "    features_list = []\n",
    "    \n",
    "    None_counter = 0\n",
    "    \n",
    "    for i in range(0, len(song_df[id_col]), batchsize):\n",
    "        \n",
    "        batch = song_df[id_col][i:i+batchsize]\n",
    "        \n",
    "        feature_results = sp.audio_features(batch)\n",
    "        \n",
    "        for i, t in enumerate(feature_results):\n",
    "            if t == None: \n",
    "                None_counter += 1\n",
    "            else: \n",
    "                features_list.append(t)\n",
    "                \n",
    "    print('Number of tracks where no audio features were available:', None_counter)\n",
    "    print('Number of usable tracks:', len(features_list))\n",
    "    \n",
    "    features_df = pd.DataFrame(features_list)\n",
    "    \n",
    "    combined_df = pd.concat([song_df, features_df], axis=1)\n",
    "    \n",
    "    return combined_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
